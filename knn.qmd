# k-nearest neighbors (KNN) algorithm

In social sciences, we are often interested in studying the variations in an outcome variable, $Y$-also known as dependent variable-conditional on a set of independent variables, $X$-also known as predictors and features.This usually is written formally as:

$$

P(Y=y|X=x)

$$
One very common strategy in modeling this conditional probability is making some assumptions about the function, $f(.)$, that maps $X$ to $Y$, and then estimating its parameters. The *Ordinary Least Square (OLS)* has been one of the oldest and the most important tools of modeling association between two variables. Under Classic Assumptions of Linear Regression, an *OLS* estimator is the *Best Linear Unbiased Estimate, (BLUE)*. However, there are situations that these assumptions do not hold. We will return to addressing the violations of some of these assumptions in the following weeks. Here, we study $K$-NN algorithm as a model-free algorithm, which impose less assumption into the prediction algorithm.Although $K$-NN does not offer useful information about the quality and quantity of association between the outcome variable and the predictors, it often is an effective predicting algorithm.


# A simple Comparison of OLS and k-NN: Boston Housing Example

Boston Housing dataset contains information on housing in the Boston, Massachusetts area in the US. Assume that we want to predict the median value of a house base on the percent of lower status population in the sub-area.The below scatter plot shows how these two variables are associated:  

```{r}

library(MASS) ## a library of example datasets
attach(Boston)

plot(lstat,medv,
     col='navy',cex=.75,
     xlab='Low Status Percent',ylab = 'Median Value($)')
```


We need a function to estimate how the housing values is associated with the percent of low status population in the neighborhood. A linear function can be one of our first candidates. That is we assume that $Y_i=\alpha+\beta X+\epsilon$. After estimating the parameters of this model, i.e. $\hat{\alpha}$ and $\hat{\beta}$, the predicted values of *OLS* estimation is $\hat{Y}=\hat \alpha +\hat \beta X$. Not surprisingly, since we assumed that the association between $X$ and $Y$ is linear, the predicted line fitted to the data is linear (Blue line in the below plot).
